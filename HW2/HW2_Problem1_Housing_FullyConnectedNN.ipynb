{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torch.optim as optim\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing dataset\n",
    "housing = pd.DataFrame(pd.read_csv(\"data/Housing.csv\")) \n",
    "housing.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing out desired features from dataset\n",
    "parameters = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking'] \n",
    "data_params = housing[parameters] \n",
    "t_u = housing[parameters] \n",
    "data_params.head() \n",
    "data_params.shape\n",
    "housing_price=housing['price']\n",
    "t_c=housing['price']\n",
    "data_price=housing_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_u = torch.tensor(t_u.values,dtype=torch.float)\n",
    "t_c = torch.tensor(t_c.values,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([545, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turning paramaters into a tensor\n",
    "data = torch.tensor(data_params.values,dtype=torch.float)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([545])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting cost to tensor\n",
    "cost = torch.tensor(data_price.values,dtype=torch.float)\n",
    "torch.unsqueeze(cost,0)\n",
    "cost.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating data into 80/20 train/val split\n",
    "n_samples = data.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "t_u_train= data[train_indices]\n",
    "t_c_train= cost[train_indices]\n",
    "t_u_val = data[val_indices]\n",
    "t_c_val = cost[val_indices]\n",
    "\n",
    "\n",
    "\n",
    "t_cn_val = F.normalize(t_c_val,dim=0)\n",
    "t_cn_train= F.normalize(t_c_train,dim=0)\n",
    "\n",
    "t_un_val = F.normalize(t_u_val,dim=0)\n",
    "t_un_train= F.normalize(t_u_train,dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()\n",
    "\n",
    "\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val,\n",
    "                  t_c_train, t_c_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p_train = model(t_u_train) \n",
    "        loss_train = loss_fn(t_p_train, t_c_train)\n",
    "\n",
    "        t_p_val = model(t_u_val) \n",
    "        loss_val = loss_fn(t_p_val, t_c_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward() \n",
    "        optimizer.step()\n",
    "            \n",
    "        if epoch == 1  or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}, Validation loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train.item(), loss_val.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeromey\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([436])) that is different to the input size (torch.Size([436, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Jeromey\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([109])) that is different to the input size (torch.Size([109, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-04 22:28:09.918132 Epoch 1, Training loss 0.028651388362050056, Validation loss 0.014564200304448605\n",
      "2022-03-04 22:28:09.924138 Epoch 10, Training loss 0.01570279523730278, Validation loss 0.0063016293570399284\n",
      "2022-03-04 22:28:09.931144 Epoch 20, Training loss 0.008127103559672832, Validation loss 0.002655675867572427\n",
      "2022-03-04 22:28:09.937149 Epoch 30, Training loss 0.004288597963750362, Validation loss 0.0016993959434330463\n",
      "2022-03-04 22:28:09.943154 Epoch 40, Training loss 0.0023459051735699177, Validation loss 0.0018503759056329727\n",
      "2022-03-04 22:28:09.949160 Epoch 50, Training loss 0.001363735762424767, Validation loss 0.002378766192123294\n",
      "2022-03-04 22:28:09.956166 Epoch 60, Training loss 0.0008676169672980905, Validation loss 0.002967244014143944\n",
      "2022-03-04 22:28:09.962172 Epoch 70, Training loss 0.0006171820568852127, Validation loss 0.0034928845707327127\n",
      "2022-03-04 22:28:09.968177 Epoch 80, Training loss 0.0004908245173282921, Validation loss 0.003920475486665964\n",
      "2022-03-04 22:28:09.974183 Epoch 90, Training loss 0.0004270887584425509, Validation loss 0.004251427482813597\n",
      "2022-03-04 22:28:09.981189 Epoch 100, Training loss 0.00039494220982305706, Validation loss 0.0045001208782196045\n",
      "2022-03-04 22:28:09.988195 Epoch 110, Training loss 0.0003787248570006341, Validation loss 0.004683530889451504\n",
      "2022-03-04 22:28:09.994201 Epoch 120, Training loss 0.0003705380659084767, Validation loss 0.004817120265215635\n",
      "2022-03-04 22:28:10.001207 Epoch 130, Training loss 0.0003663988900370896, Validation loss 0.004913595505058765\n",
      "2022-03-04 22:28:10.008214 Epoch 140, Training loss 0.0003642997471615672, Validation loss 0.0049828398041427135\n",
      "2022-03-04 22:28:10.014220 Epoch 150, Training loss 0.00036322843516245484, Validation loss 0.005032312124967575\n",
      "2022-03-04 22:28:10.020224 Epoch 160, Training loss 0.00036267517134547234, Validation loss 0.0050675286911427975\n",
      "2022-03-04 22:28:10.026230 Epoch 170, Training loss 0.00036238282336853445, Validation loss 0.005092511419206858\n",
      "2022-03-04 22:28:10.033236 Epoch 180, Training loss 0.00036222205380909145, Validation loss 0.005110170692205429\n",
      "2022-03-04 22:28:10.040243 Epoch 190, Training loss 0.0003621275827754289, Validation loss 0.005122609902173281\n",
      "2022-03-04 22:28:10.046248 Epoch 200, Training loss 0.0003620664938353002, Validation loss 0.005131323356181383\n",
      "2022-03-04 22:28:10.053255 Epoch 210, Training loss 0.00036202219780534506, Validation loss 0.005137389525771141\n",
      "2022-03-04 22:28:10.059260 Epoch 220, Training loss 0.00036198642919771373, Validation loss 0.005141571629792452\n",
      "2022-03-04 22:28:10.066267 Epoch 230, Training loss 0.0003619549097493291, Validation loss 0.005144414957612753\n",
      "2022-03-04 22:28:10.072272 Epoch 240, Training loss 0.00036192554398439825, Validation loss 0.005146305076777935\n",
      "2022-03-04 22:28:10.078277 Epoch 250, Training loss 0.0003618972550611943, Validation loss 0.005147518124431372\n",
      "2022-03-04 22:28:10.086284 Epoch 260, Training loss 0.00036186951911076903, Validation loss 0.005148249678313732\n",
      "2022-03-04 22:28:10.092290 Epoch 270, Training loss 0.00036184207419864833, Validation loss 0.005148644559085369\n",
      "2022-03-04 22:28:10.098295 Epoch 280, Training loss 0.0003618148039095104, Validation loss 0.005148799158632755\n",
      "2022-03-04 22:28:10.104301 Epoch 290, Training loss 0.00036178765003569424, Validation loss 0.005148781929165125\n",
      "2022-03-04 22:28:10.110306 Epoch 300, Training loss 0.00036176052526570857, Validation loss 0.005148638971149921\n"
     ]
    }
   ],
   "source": [
    "#First model with following hidden layer size..\n",
    "#    1st hidden layer = 8\n",
    "\n",
    "seq_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(5, 8)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(8, 1))\n",
    "]))\n",
    "\n",
    "optimizer = optim.SGD(seq_model.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 300, \n",
    "    optimizer = optimizer,\n",
    "    model = seq_model,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    t_u_train = t_un_train,\n",
    "    t_u_val = t_un_val, \n",
    "    t_c_train = t_cn_train,\n",
    "    t_c_val = t_cn_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_linear.weight torch.Size([8, 5])\n",
      "hidden_linear.bias torch.Size([8])\n",
      "output_linear.weight torch.Size([1, 8])\n",
      "output_linear.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "seq_model\n",
    "\n",
    "for price, param in seq_model.named_parameters():\n",
    "    print(price, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.3977, -0.2150,  0.2646,  0.1530,  0.1002],\n",
       "         [ 0.2447,  0.2429, -0.1354,  0.3185, -0.1918],\n",
       "         [ 0.2127, -0.0214, -0.1124,  0.4138,  0.1655],\n",
       "         [ 0.2770, -0.0083, -0.0936, -0.3290, -0.4305],\n",
       "         [-0.3736, -0.3984, -0.2914, -0.4154, -0.4441],\n",
       "         [ 0.0920, -0.2390, -0.0269,  0.0157, -0.2983],\n",
       "         [ 0.0879, -0.1470, -0.2385, -0.4022,  0.3040],\n",
       "         [-0.4166,  0.1021,  0.4130,  0.2814,  0.0130]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0922,  0.2776, -0.1572, -0.3498, -0.3853, -0.0957, -0.2216,\n",
       "          0.1180], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.1311,  0.1615, -0.0231,  0.0229,  0.1894,  0.2741, -0.0847,\n",
       "          -0.1692]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1307], requires_grad=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(seq_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.1307], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.output_linear.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-04 22:28:10.184374 Epoch 1, Training loss 0.0035714362747967243, Validation loss 0.0016199146630242467\n",
      "2022-03-04 22:28:10.195384 Epoch 10, Training loss 0.0014971073251217604, Validation loss 0.0015192347345873713\n",
      "2022-03-04 22:28:10.207394 Epoch 20, Training loss 0.0006887711933813989, Validation loss 0.0020097861997783184\n",
      "2022-03-04 22:28:10.221407 Epoch 30, Training loss 0.0004246427852194756, Validation loss 0.002489412436261773\n",
      "2022-03-04 22:28:10.234419 Epoch 40, Training loss 0.0003386647440493107, Validation loss 0.0028282084967941046\n",
      "2022-03-04 22:28:10.246430 Epoch 50, Training loss 0.0003107429656665772, Validation loss 0.003042487194761634\n",
      "2022-03-04 22:28:10.259442 Epoch 60, Training loss 0.00030168716330081224, Validation loss 0.0031713994685560465\n",
      "2022-03-04 22:28:10.271453 Epoch 70, Training loss 0.0002987523621413857, Validation loss 0.0032470047008246183\n",
      "2022-03-04 22:28:10.284465 Epoch 80, Training loss 0.00029780136537738144, Validation loss 0.003290744498372078\n",
      "2022-03-04 22:28:10.297476 Epoch 90, Training loss 0.0002974929811898619, Validation loss 0.003315857145935297\n",
      "2022-03-04 22:28:10.310488 Epoch 100, Training loss 0.0002973926311824471, Validation loss 0.003330210456624627\n",
      "2022-03-04 22:28:10.322499 Epoch 110, Training loss 0.0002973597147502005, Validation loss 0.0033383879344910383\n",
      "2022-03-04 22:28:10.336512 Epoch 120, Training loss 0.00029734859708696604, Validation loss 0.003343037562444806\n",
      "2022-03-04 22:28:10.348523 Epoch 130, Training loss 0.00029734455165453255, Validation loss 0.0033456715755164623\n",
      "2022-03-04 22:28:10.360533 Epoch 140, Training loss 0.00029734280542470515, Validation loss 0.003347157733514905\n",
      "2022-03-04 22:28:10.373545 Epoch 150, Training loss 0.00029734172858297825, Validation loss 0.003347987774759531\n",
      "2022-03-04 22:28:10.385556 Epoch 160, Training loss 0.0002973409718833864, Validation loss 0.0033484487794339657\n",
      "2022-03-04 22:28:10.398568 Epoch 170, Training loss 0.00029734024428762496, Validation loss 0.003348702099174261\n",
      "2022-03-04 22:28:10.410579 Epoch 180, Training loss 0.00029733957489952445, Validation loss 0.0033488331828266382\n",
      "2022-03-04 22:28:10.423861 Epoch 190, Training loss 0.00029733890551142395, Validation loss 0.0033488969784229994\n",
      "2022-03-04 22:28:10.454889 Epoch 200, Training loss 0.000297338207019493, Validation loss 0.003348920727148652\n",
      "2022-03-04 22:28:10.466900 Epoch 210, Training loss 0.0002973375376313925, Validation loss 0.003348921425640583\n",
      "2022-03-04 22:28:10.479912 Epoch 220, Training loss 0.00029733689734712243, Validation loss 0.0033489083871245384\n",
      "2022-03-04 22:28:10.492924 Epoch 230, Training loss 0.00029733619885519147, Validation loss 0.0033488913904875517\n",
      "2022-03-04 22:28:10.504935 Epoch 240, Training loss 0.00029733552946709096, Validation loss 0.0033488727640360594\n",
      "2022-03-04 22:28:10.518947 Epoch 250, Training loss 0.00029733486007899046, Validation loss 0.003348850877955556\n",
      "2022-03-04 22:28:10.532960 Epoch 260, Training loss 0.00029733419069088995, Validation loss 0.003348828060552478\n",
      "2022-03-04 22:28:10.545972 Epoch 270, Training loss 0.00029733346309512854, Validation loss 0.003348803613334894\n",
      "2022-03-04 22:28:10.557983 Epoch 280, Training loss 0.0002973328228108585, Validation loss 0.003348778933286667\n",
      "2022-03-04 22:28:10.569994 Epoch 290, Training loss 0.00029733218252658844, Validation loss 0.003348752623423934\n",
      "2022-03-04 22:28:10.582005 Epoch 300, Training loss 0.0002973314840346575, Validation loss 0.003348724916577339\n"
     ]
    }
   ],
   "source": [
    "#Second model with following hidden layer size..\n",
    "#    1st hidden layer =8\n",
    "#    2nd hidden layer = 80\n",
    "#    3rd hidden layer = 20\n",
    "seq_model = nn.Sequential(\n",
    "     nn.Linear(5, 8),\n",
    "     nn.Tanh(),\n",
    "     nn.Linear(8, 80),\n",
    "     nn.Tanh(),\n",
    "     nn.Linear(80, 20),\n",
    "     nn.Tanh(),\n",
    "     nn.Linear(20, 1))\n",
    "\n",
    "optimizer = optim.SGD(seq_model.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 300, \n",
    "    optimizer = optimizer,\n",
    "    model = seq_model,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    t_u_train = t_un_train,\n",
    "    t_u_val = t_un_val, \n",
    "    t_c_train = t_cn_train,\n",
    "    t_c_val = t_cn_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.1373, -0.0156,  0.0818,  0.0031, -0.3313],\n",
       "         [-0.0875,  0.2662, -0.4049,  0.3106,  0.2989],\n",
       "         [-0.3503, -0.4207,  0.4164,  0.1899,  0.3309],\n",
       "         [ 0.1285, -0.2973, -0.3550,  0.1005, -0.0111],\n",
       "         [-0.2541,  0.3821,  0.3074,  0.0941,  0.1438],\n",
       "         [ 0.3906,  0.4204, -0.1065, -0.1923, -0.0641],\n",
       "         [-0.3960, -0.1637,  0.2401, -0.3826, -0.3300],\n",
       "         [ 0.4185, -0.1176,  0.0901, -0.2188, -0.2253]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1394, -0.4427, -0.3844, -0.3718, -0.3950,  0.0229, -0.2412,\n",
       "         -0.4430], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.2562, -0.0044,  0.2494,  0.1027,  0.1480, -0.0035, -0.0149,\n",
       "          -0.0917],\n",
       "         [-0.2096,  0.2282, -0.1149,  0.0604, -0.2841, -0.0975, -0.2280,\n",
       "           0.3529],\n",
       "         [-0.2309, -0.3491, -0.0332,  0.0562,  0.0495, -0.0805, -0.2340,\n",
       "           0.1657],\n",
       "         [ 0.3100,  0.2329,  0.0300, -0.2360, -0.0362, -0.2601,  0.2616,\n",
       "          -0.0374],\n",
       "         [ 0.1670,  0.2242,  0.0232,  0.2371, -0.1016,  0.2594,  0.0792,\n",
       "          -0.0274],\n",
       "         [ 0.2717,  0.2419, -0.3409, -0.2742,  0.1403,  0.1160, -0.0949,\n",
       "          -0.0059],\n",
       "         [ 0.3060, -0.0829, -0.1814,  0.3487,  0.1166,  0.1083, -0.1664,\n",
       "           0.2014],\n",
       "         [ 0.3087,  0.2719, -0.2125, -0.0493,  0.0802, -0.0676,  0.2224,\n",
       "          -0.0535],\n",
       "         [-0.0333,  0.1515, -0.2951, -0.2298, -0.2112,  0.2542,  0.2306,\n",
       "           0.1215],\n",
       "         [-0.0254,  0.2907,  0.0281,  0.3034,  0.2445,  0.0658,  0.0769,\n",
       "          -0.0090],\n",
       "         [ 0.0587, -0.1049, -0.3434, -0.1476,  0.3203,  0.0753,  0.3291,\n",
       "           0.1112],\n",
       "         [ 0.2121,  0.2404, -0.0057,  0.0650,  0.1041,  0.3236,  0.3368,\n",
       "           0.2620],\n",
       "         [-0.2038, -0.1464, -0.2511, -0.3503, -0.0824, -0.0395, -0.2005,\n",
       "           0.2311],\n",
       "         [-0.0545, -0.2465,  0.3122,  0.2605, -0.0331,  0.2837,  0.1096,\n",
       "           0.2920],\n",
       "         [-0.3311, -0.2652,  0.1052, -0.0974, -0.3083, -0.0952,  0.1238,\n",
       "          -0.2525],\n",
       "         [-0.2741,  0.0986, -0.2621,  0.0459,  0.2612,  0.1584, -0.0671,\n",
       "          -0.1249],\n",
       "         [ 0.0399, -0.0704,  0.3373,  0.1889,  0.1139,  0.2900,  0.0340,\n",
       "          -0.0412],\n",
       "         [-0.2194, -0.0846, -0.1322,  0.0105, -0.1666, -0.1779,  0.0732,\n",
       "          -0.1037],\n",
       "         [ 0.1758, -0.2125,  0.3155, -0.0863, -0.1752,  0.3314,  0.0744,\n",
       "          -0.3032],\n",
       "         [ 0.2108,  0.0457,  0.2074, -0.0511,  0.0882, -0.0968, -0.1881,\n",
       "           0.0170],\n",
       "         [ 0.0038, -0.2803, -0.0673, -0.1199,  0.1292, -0.0906, -0.3512,\n",
       "          -0.1760],\n",
       "         [ 0.0848,  0.3482,  0.3392,  0.1995, -0.1057,  0.3073,  0.1134,\n",
       "           0.1104],\n",
       "         [ 0.0071,  0.3508,  0.1398,  0.0462,  0.0451,  0.0642, -0.3003,\n",
       "          -0.1418],\n",
       "         [ 0.2285, -0.1288, -0.2504, -0.0728, -0.2427,  0.1848,  0.1055,\n",
       "          -0.1351],\n",
       "         [ 0.0073, -0.2485, -0.2992,  0.1178,  0.0662,  0.1834, -0.3197,\n",
       "           0.0704],\n",
       "         [-0.2037,  0.2719, -0.1825, -0.2940, -0.1910,  0.2546, -0.3356,\n",
       "          -0.1229],\n",
       "         [-0.3488,  0.0828,  0.0015, -0.1176,  0.2570, -0.1932,  0.3467,\n",
       "           0.0357],\n",
       "         [ 0.0376, -0.2480, -0.2921, -0.2082, -0.2550,  0.1912,  0.0612,\n",
       "           0.3482],\n",
       "         [ 0.1465, -0.3151, -0.3089, -0.0092,  0.0699, -0.3047,  0.1380,\n",
       "          -0.2761],\n",
       "         [-0.0283, -0.0608,  0.0387,  0.1330, -0.3320,  0.0121, -0.3354,\n",
       "          -0.1950],\n",
       "         [-0.2679,  0.1608,  0.2022,  0.0562, -0.2245, -0.3336,  0.3381,\n",
       "          -0.2928],\n",
       "         [ 0.2169,  0.2436,  0.0776, -0.2863, -0.1417, -0.2708,  0.0068,\n",
       "           0.0935],\n",
       "         [ 0.0631,  0.0386, -0.1351, -0.2213, -0.0222,  0.2273, -0.0073,\n",
       "           0.2433],\n",
       "         [ 0.1650,  0.0944,  0.1078,  0.0063, -0.2977,  0.2681, -0.1486,\n",
       "          -0.0483],\n",
       "         [-0.1605,  0.1622, -0.0424, -0.0421,  0.2253, -0.2377, -0.3121,\n",
       "           0.0350],\n",
       "         [ 0.1830, -0.3059, -0.0766, -0.0902,  0.1532, -0.0390, -0.0034,\n",
       "          -0.2318],\n",
       "         [-0.0658, -0.1762,  0.1119,  0.2793, -0.2308,  0.0827, -0.2642,\n",
       "           0.2244],\n",
       "         [-0.1282, -0.1943, -0.3452,  0.2970,  0.2987, -0.1062, -0.3187,\n",
       "          -0.0270],\n",
       "         [ 0.0501,  0.3381,  0.1614, -0.2827,  0.2743,  0.1123, -0.2454,\n",
       "          -0.0727],\n",
       "         [-0.3136, -0.0199,  0.3064, -0.1574,  0.3128,  0.2161, -0.0605,\n",
       "           0.1011],\n",
       "         [-0.0909,  0.0748, -0.0263,  0.3142, -0.2985, -0.1642,  0.1801,\n",
       "           0.0441],\n",
       "         [-0.0320, -0.2857,  0.2017, -0.3406, -0.3015, -0.0487,  0.1071,\n",
       "          -0.2822],\n",
       "         [-0.2827,  0.2489,  0.0221,  0.0714,  0.1037, -0.3255,  0.2746,\n",
       "          -0.2901],\n",
       "         [-0.1820,  0.1245,  0.1107,  0.1136, -0.3382,  0.3389,  0.2960,\n",
       "          -0.1731],\n",
       "         [-0.0350, -0.2026,  0.1865,  0.2748, -0.2810, -0.2233,  0.0762,\n",
       "           0.2110],\n",
       "         [ 0.1870,  0.0243, -0.1732, -0.0551,  0.1593,  0.2136, -0.2694,\n",
       "           0.3251],\n",
       "         [-0.0753,  0.1593,  0.2667,  0.1001, -0.2385, -0.2009,  0.1444,\n",
       "          -0.0402],\n",
       "         [-0.0892,  0.3003,  0.1400, -0.3079, -0.2074,  0.0776, -0.0987,\n",
       "          -0.1253],\n",
       "         [-0.1619,  0.0675, -0.2580,  0.1983,  0.0691, -0.2260, -0.1167,\n",
       "           0.1126],\n",
       "         [-0.1633,  0.1587,  0.3000,  0.0342, -0.0039,  0.3503, -0.1547,\n",
       "           0.1485],\n",
       "         [-0.2532, -0.2331,  0.0775, -0.0891,  0.0866,  0.1934,  0.2350,\n",
       "          -0.3425],\n",
       "         [-0.2788,  0.2229, -0.1539, -0.2844, -0.2229,  0.1349, -0.1699,\n",
       "          -0.0366],\n",
       "         [ 0.1129, -0.0191, -0.2163, -0.3233,  0.0586,  0.1251, -0.0496,\n",
       "          -0.2555],\n",
       "         [ 0.2930, -0.1715, -0.0450,  0.2882,  0.2363, -0.1852,  0.1427,\n",
       "          -0.2379],\n",
       "         [ 0.0969, -0.2513,  0.1824, -0.1975, -0.2705,  0.1140,  0.3024,\n",
       "           0.2239],\n",
       "         [ 0.2417, -0.0756, -0.2746,  0.3293,  0.0993, -0.2663, -0.1820,\n",
       "           0.2833],\n",
       "         [-0.0024,  0.1402,  0.3358,  0.3228, -0.2992, -0.1803,  0.3418,\n",
       "          -0.1114],\n",
       "         [ 0.2619, -0.0801, -0.0944, -0.1127,  0.2605, -0.1031,  0.0458,\n",
       "          -0.2002],\n",
       "         [-0.3261, -0.3158,  0.2434,  0.2458,  0.0136, -0.2702,  0.0544,\n",
       "          -0.1469],\n",
       "         [-0.1944,  0.3406,  0.3330, -0.3037,  0.1958,  0.1158, -0.0950,\n",
       "          -0.3358],\n",
       "         [-0.3290, -0.0324, -0.0523,  0.3134,  0.1148,  0.2818, -0.1472,\n",
       "           0.0641],\n",
       "         [ 0.0903,  0.3268, -0.3365, -0.2494,  0.2458,  0.0818, -0.0609,\n",
       "          -0.2474],\n",
       "         [ 0.1043, -0.0874,  0.1260,  0.2415, -0.3219, -0.2849,  0.1600,\n",
       "          -0.1639],\n",
       "         [ 0.3037,  0.1128, -0.2716, -0.3404,  0.1440,  0.0787,  0.0335,\n",
       "          -0.2090],\n",
       "         [-0.3161, -0.3122,  0.3089,  0.2545, -0.2276,  0.1315,  0.0365,\n",
       "          -0.1159],\n",
       "         [ 0.3211,  0.0420,  0.1288,  0.0867,  0.0586, -0.2486,  0.1704,\n",
       "           0.1139],\n",
       "         [ 0.2073,  0.1514,  0.0895, -0.1696,  0.0619,  0.3339, -0.1036,\n",
       "          -0.0638],\n",
       "         [ 0.2084, -0.1590, -0.1906, -0.0051,  0.3277, -0.2782, -0.0100,\n",
       "           0.1234],\n",
       "         [ 0.2775, -0.3336,  0.0415,  0.0930, -0.2690, -0.2090, -0.0028,\n",
       "          -0.2367],\n",
       "         [ 0.2370,  0.0293, -0.0004,  0.0329, -0.2250,  0.0809,  0.1489,\n",
       "           0.1333],\n",
       "         [-0.2707,  0.2467, -0.3074, -0.0268, -0.1538,  0.2654, -0.1339,\n",
       "          -0.2416],\n",
       "         [-0.1348, -0.0179, -0.0053,  0.1748, -0.1143,  0.2346,  0.2737,\n",
       "          -0.1831],\n",
       "         [-0.2933, -0.0070, -0.2584,  0.1376,  0.0201,  0.0094, -0.2216,\n",
       "           0.3145],\n",
       "         [ 0.3298, -0.3230,  0.1255, -0.2542,  0.2413, -0.0248, -0.1718,\n",
       "          -0.3230],\n",
       "         [-0.0727,  0.1447, -0.1937,  0.0183,  0.2058, -0.1360,  0.2397,\n",
       "           0.1313],\n",
       "         [ 0.2855,  0.3361, -0.2509,  0.2851,  0.2811, -0.0178,  0.2753,\n",
       "           0.1916],\n",
       "         [-0.2591, -0.2523,  0.1109,  0.0478, -0.1520,  0.1793,  0.2501,\n",
       "          -0.0194],\n",
       "         [ 0.3181,  0.2445, -0.2681, -0.1066,  0.2250,  0.2357, -0.1399,\n",
       "           0.0031],\n",
       "         [ 0.1969, -0.2566,  0.1201, -0.0832,  0.3072, -0.3267,  0.2221,\n",
       "           0.0728],\n",
       "         [-0.1018, -0.1928, -0.1094, -0.3263,  0.2764, -0.2817,  0.3372,\n",
       "           0.1488]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1614, -0.2633, -0.3063, -0.0925,  0.2337,  0.2234, -0.2665,\n",
       "          0.1382,  0.0583, -0.2283, -0.0556,  0.1206,  0.2239,  0.0319,\n",
       "         -0.0570, -0.2569,  0.1955, -0.0264, -0.0891,  0.2332, -0.2948,\n",
       "         -0.1091,  0.1851, -0.2136,  0.0900,  0.2813,  0.2998,  0.1795,\n",
       "         -0.1664, -0.0985,  0.3450,  0.0603,  0.3428,  0.0813, -0.0500,\n",
       "          0.1246, -0.1276,  0.0186, -0.1407,  0.0108, -0.0405,  0.3209,\n",
       "          0.1118,  0.1645, -0.2790,  0.1176,  0.0082,  0.3524,  0.1317,\n",
       "          0.1445, -0.1371,  0.0813,  0.1893, -0.0094,  0.0623, -0.1994,\n",
       "          0.1014,  0.2845, -0.2094, -0.0364, -0.2294, -0.0045,  0.2680,\n",
       "         -0.1862,  0.1926,  0.1133,  0.1651, -0.1076, -0.1369, -0.2530,\n",
       "          0.0117,  0.0256, -0.2316,  0.0772, -0.0095, -0.1474,  0.1395,\n",
       "          0.2546,  0.1630,  0.0942], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1013, -0.0163,  ..., -0.0483,  0.0029],\n",
       "         [-0.0455,  0.0344,  ..., -0.0115, -0.0855],\n",
       "         ...,\n",
       "         [ 0.0388, -0.0722,  ..., -0.0158,  0.0253],\n",
       "         [-0.0820, -0.0370,  ..., -0.0257, -0.0572]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1110, -0.0533,  0.1047, -0.0389,  0.0980,  0.0550,  0.0739,\n",
       "         -0.0670,  0.0023, -0.0410,  0.1066, -0.0864,  0.0094, -0.0579,\n",
       "          0.0709, -0.0917, -0.0906,  0.0026,  0.1124, -0.0995],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1734, -0.0640, -0.1202, -0.0343, -0.0766, -0.0615, -0.0158,\n",
       "           0.2039, -0.0362,  0.0840,  0.0320,  0.0168, -0.0464, -0.1560,\n",
       "           0.0355, -0.0478, -0.0559,  0.0937, -0.1150, -0.1398]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1454], requires_grad=True)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(seq_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Sequential(\n",
       "  (0): Linear(in_features=5, out_features=8, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=8, out_features=80, bias=True)\n",
       "  (3): Tanh()\n",
       "  (4): Linear(in_features=80, out_features=20, bias=True)\n",
       "  (5): Tanh()\n",
       "  (6): Linear(in_features=20, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=5, out_features=8, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=8, out_features=80, bias=True)\n",
       "  (3): Tanh()\n",
       "  (4): Linear(in_features=80, out_features=20, bias=True)\n",
       "  (5): Tanh()\n",
       "  (6): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([8, 5]),\n",
       " torch.Size([8]),\n",
       " torch.Size([80, 8]),\n",
       " torch.Size([80]),\n",
       " torch.Size([20, 80]),\n",
       " torch.Size([20]),\n",
       " torch.Size([1, 20]),\n",
       " torch.Size([1])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param.shape for param in seq_model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
