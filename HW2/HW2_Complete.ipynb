{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8980e5a1",
   "metadata": {},
   "source": [
    "Jeromey Schwartz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4531f1",
   "metadata": {},
   "source": [
    "HW2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee673c",
   "metadata": {},
   "source": [
    "801055747"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9425033",
   "metadata": {},
   "source": [
    "https://github.com/JS-CTRL/RealTimeAI/tree/main/HW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1006a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adb83ef0",
   "metadata": {},
   "source": [
    "Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20496007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torch.optim as optim\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "666d7095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing dataset\n",
    "housing = pd.DataFrame(pd.read_csv(\"data/Housing.csv\")) \n",
    "housing.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf531538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing out desired features from dataset\n",
    "parameters = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking'] \n",
    "data_params = housing[parameters] \n",
    "t_u = housing[parameters] \n",
    "data_params.head() \n",
    "data_params.shape\n",
    "housing_price=housing['price']\n",
    "t_c=housing['price']\n",
    "data_price=housing_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e77e568",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_u = torch.tensor(t_u.values,dtype=torch.float)\n",
    "t_c = torch.tensor(t_c.values,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "306d2421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([545, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turning paramaters into a tensor\n",
    "data = torch.tensor(data_params.values,dtype=torch.float)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c4db380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([545])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting cost to tensor\n",
    "cost = torch.tensor(data_price.values,dtype=torch.float)\n",
    "torch.unsqueeze(cost,0)\n",
    "cost.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcffb8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating data into 80/20 train/val split\n",
    "n_samples = data.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "t_u_train= data[train_indices]\n",
    "t_c_train= cost[train_indices]\n",
    "t_u_val = data[val_indices]\n",
    "t_c_val = cost[val_indices]\n",
    "\n",
    "\n",
    "\n",
    "t_cn_val = F.normalize(t_c_val,dim=0)\n",
    "t_cn_train= F.normalize(t_c_train,dim=0)\n",
    "\n",
    "t_un_val = F.normalize(t_u_val,dim=0)\n",
    "t_un_train= F.normalize(t_u_train,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee88d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()\n",
    "\n",
    "\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val,\n",
    "                  t_c_train, t_c_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p_train = model(t_u_train) # <1>\n",
    "        loss_train = loss_fn(t_p_train, t_c_train)\n",
    "\n",
    "        t_p_val = model(t_u_val) # <1>\n",
    "        loss_val = loss_fn(t_p_val, t_c_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward() # <2>\n",
    "        optimizer.step()\n",
    "            \n",
    "        if epoch == 1  or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}, Validation loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train.item(), loss_val.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0822d10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeromey\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([436])) that is different to the input size (torch.Size([436, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Jeromey\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([109])) that is different to the input size (torch.Size([109, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-04 22:30:15.312648 Epoch 1, Training loss 0.03358231484889984, Validation loss 0.02186567708849907\n",
      "2022-03-04 22:30:15.318653 Epoch 10, Training loss 0.01732766255736351, Validation loss 0.009677144698798656\n",
      "2022-03-04 22:30:15.324659 Epoch 20, Training loss 0.008351471275091171, Validation loss 0.003934876527637243\n",
      "2022-03-04 22:30:15.330664 Epoch 30, Training loss 0.004090785048902035, Validation loss 0.0019294505473226309\n",
      "2022-03-04 22:30:15.337670 Epoch 40, Training loss 0.0020764213986694813, Validation loss 0.0014788457192480564\n",
      "2022-03-04 22:30:15.343676 Epoch 50, Training loss 0.001126956194639206, Validation loss 0.001609200844541192\n",
      "2022-03-04 22:30:15.349681 Epoch 60, Training loss 0.0006804285221733153, Validation loss 0.0019061375642195344\n",
      "2022-03-04 22:30:15.356687 Epoch 70, Training loss 0.0004707613552454859, Validation loss 0.00220731133595109\n",
      "2022-03-04 22:30:15.362693 Epoch 80, Training loss 0.00037242475082166493, Validation loss 0.0024594722781330347\n",
      "2022-03-04 22:30:15.368698 Epoch 90, Training loss 0.00032633906812407076, Validation loss 0.002653634874150157\n",
      "2022-03-04 22:30:15.374704 Epoch 100, Training loss 0.00030475229141302407, Validation loss 0.002796616405248642\n",
      "2022-03-04 22:30:15.379708 Epoch 110, Training loss 0.00029464493854902685, Validation loss 0.0028991810977458954\n",
      "2022-03-04 22:30:15.386715 Epoch 120, Training loss 0.00028991347062401474, Validation loss 0.002971567213535309\n",
      "2022-03-04 22:30:15.392720 Epoch 130, Training loss 0.0002876989310607314, Validation loss 0.003022121964022517\n",
      "2022-03-04 22:30:15.400728 Epoch 140, Training loss 0.0002866624272428453, Validation loss 0.003057188121601939\n",
      "2022-03-04 22:30:15.407734 Epoch 150, Training loss 0.0002861772372853011, Validation loss 0.003081400878727436\n",
      "2022-03-04 22:30:15.413739 Epoch 160, Training loss 0.00028595011099241674, Validation loss 0.0030980659648776054\n",
      "2022-03-04 22:30:15.420746 Epoch 170, Training loss 0.00028584367828443646, Validation loss 0.003109513083472848\n",
      "2022-03-04 22:30:15.426751 Epoch 180, Training loss 0.0002857936779037118, Validation loss 0.003117365064099431\n",
      "2022-03-04 22:30:15.433757 Epoch 190, Training loss 0.00028577016200870275, Validation loss 0.003122742986306548\n",
      "2022-03-04 22:30:15.439763 Epoch 200, Training loss 0.0002857589570339769, Validation loss 0.003126425202935934\n",
      "2022-03-04 22:30:15.445769 Epoch 210, Training loss 0.0002857536019291729, Validation loss 0.003128943732008338\n",
      "2022-03-04 22:30:15.451774 Epoch 220, Training loss 0.00028575092437677085, Validation loss 0.0031306627206504345\n",
      "2022-03-04 22:30:15.458780 Epoch 230, Training loss 0.00028574952739290893, Validation loss 0.00313183874823153\n",
      "2022-03-04 22:30:15.464786 Epoch 240, Training loss 0.00028574871248565614, Validation loss 0.003132640616968274\n",
      "2022-03-04 22:30:15.470791 Epoch 250, Training loss 0.00028574815951287746, Validation loss 0.0031331877689808607\n",
      "2022-03-04 22:30:15.476797 Epoch 260, Training loss 0.00028574769385159016, Validation loss 0.003133561462163925\n",
      "2022-03-04 22:30:15.482802 Epoch 270, Training loss 0.00028574737370945513, Validation loss 0.003133813152089715\n",
      "2022-03-04 22:30:15.490809 Epoch 280, Training loss 0.0002857470535673201, Validation loss 0.003133984049782157\n",
      "2022-03-04 22:30:15.497816 Epoch 290, Training loss 0.0002857467334251851, Validation loss 0.003134095575660467\n",
      "2022-03-04 22:30:15.504822 Epoch 300, Training loss 0.0002857464423868805, Validation loss 0.003134173108264804\n"
     ]
    }
   ],
   "source": [
    "#First model with following hidden layer size..\n",
    "#    1st hidden layer = 8\n",
    "\n",
    "seq_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(5, 8)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(8, 1))\n",
    "]))\n",
    "\n",
    "optimizer = optim.SGD(seq_model.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 300, \n",
    "    optimizer = optimizer,\n",
    "    model = seq_model,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    t_u_train = t_un_train,\n",
    "    t_u_val = t_un_val, \n",
    "    t_c_train = t_cn_train,\n",
    "    t_c_val = t_cn_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64136f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_linear.weight torch.Size([8, 5])\n",
      "hidden_linear.bias torch.Size([8])\n",
      "output_linear.weight torch.Size([1, 8])\n",
      "output_linear.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "seq_model\n",
    "\n",
    "for price, param in seq_model.named_parameters():\n",
    "    print(price, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37e3e828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0997,  0.2240,  0.0728, -0.1972,  0.3285],\n",
       "         [-0.0045,  0.3910, -0.0107,  0.2389,  0.2687],\n",
       "         [-0.4047,  0.1795, -0.1614,  0.3065,  0.0596],\n",
       "         [ 0.4354, -0.3719,  0.0869, -0.3118, -0.4350],\n",
       "         [ 0.0150, -0.2132,  0.3208, -0.2917, -0.1347],\n",
       "         [-0.2949,  0.3523, -0.3177, -0.3615,  0.3291],\n",
       "         [ 0.4198, -0.4391, -0.4002,  0.2026, -0.2789],\n",
       "         [-0.0358,  0.0134, -0.3117,  0.3830,  0.2179]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3543,  0.0880, -0.0192, -0.3314, -0.2405,  0.2807,  0.0261,\n",
       "          0.4517], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.1870,  0.2947,  0.2859,  0.1813,  0.0051,  0.0104,  0.2129,\n",
       "          -0.2578]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2456], requires_grad=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(seq_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "968a9224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.2456], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.output_linear.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3466034c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-04 22:30:15.562875 Epoch 1, Training loss 0.022394826635718346, Validation loss 0.03859438747167587\n",
      "2022-03-04 22:30:15.574886 Epoch 10, Training loss 0.005526605527848005, Validation loss 0.014969206415116787\n",
      "2022-03-04 22:30:15.586896 Epoch 20, Training loss 0.001343531534075737, Validation loss 0.007277234457433224\n",
      "2022-03-04 22:30:15.598907 Epoch 30, Training loss 0.0005030253669247031, Validation loss 0.004867547191679478\n",
      "2022-03-04 22:30:15.611919 Epoch 40, Training loss 0.0003350460610818118, Validation loss 0.003998683299869299\n",
      "2022-03-04 22:30:15.623930 Epoch 50, Training loss 0.00030157214496284723, Validation loss 0.003652431769296527\n",
      "2022-03-04 22:30:15.636942 Epoch 60, Training loss 0.0002949087065644562, Validation loss 0.0035062336828559637\n",
      "2022-03-04 22:30:15.647952 Epoch 70, Training loss 0.00029358058236539364, Validation loss 0.0034426480997353792\n",
      "2022-03-04 22:30:15.659963 Epoch 80, Training loss 0.0002933134092018008, Validation loss 0.00341458129696548\n",
      "2022-03-04 22:30:15.671974 Epoch 90, Training loss 0.00029325715149752796, Validation loss 0.0034020887687802315\n",
      "2022-03-04 22:30:15.683985 Epoch 100, Training loss 0.0002932428033091128, Validation loss 0.0033964859321713448\n",
      "2022-03-04 22:30:15.697998 Epoch 110, Training loss 0.00029323677881620824, Validation loss 0.0033939452841877937\n",
      "2022-03-04 22:30:15.711010 Epoch 120, Training loss 0.0002932324423454702, Validation loss 0.00339277065359056\n",
      "2022-03-04 22:30:15.724021 Epoch 130, Training loss 0.0002932283969130367, Validation loss 0.003392198821529746\n",
      "2022-03-04 22:30:15.738034 Epoch 140, Training loss 0.00029322446789592505, Validation loss 0.0033919005654752254\n",
      "2022-03-04 22:30:15.751046 Epoch 150, Training loss 0.00029322050977498293, Validation loss 0.0033917210530489683\n",
      "2022-03-04 22:30:15.765058 Epoch 160, Training loss 0.0002932165516540408, Validation loss 0.0033915943931788206\n",
      "2022-03-04 22:30:15.778070 Epoch 170, Training loss 0.00029321262263692915, Validation loss 0.003391491947695613\n",
      "2022-03-04 22:30:15.791082 Epoch 180, Training loss 0.00029320866451598704, Validation loss 0.0033914020750671625\n",
      "2022-03-04 22:30:15.805095 Epoch 190, Training loss 0.0002932047354988754, Validation loss 0.0033913166262209415\n",
      "2022-03-04 22:30:15.818106 Epoch 200, Training loss 0.00029320077737793326, Validation loss 0.00339123304001987\n",
      "2022-03-04 22:30:15.831119 Epoch 210, Training loss 0.0002931968483608216, Validation loss 0.0033911506179720163\n",
      "2022-03-04 22:30:15.845131 Epoch 220, Training loss 0.00029319297755137086, Validation loss 0.003391067497432232\n",
      "2022-03-04 22:30:15.859144 Epoch 230, Training loss 0.00029318901943042874, Validation loss 0.0033909848425537348\n",
      "2022-03-04 22:30:15.871155 Epoch 240, Training loss 0.0002931850904133171, Validation loss 0.0033909021876752377\n",
      "2022-03-04 22:30:15.884167 Epoch 250, Training loss 0.0002931811613962054, Validation loss 0.003390819998458028\n",
      "2022-03-04 22:30:15.897178 Epoch 260, Training loss 0.0002931772032752633, Validation loss 0.0033907373435795307\n",
      "2022-03-04 22:30:15.910190 Epoch 270, Training loss 0.0002931733033619821, Validation loss 0.003390655154362321\n",
      "2022-03-04 22:30:15.923202 Epoch 280, Training loss 0.0002931694034487009, Validation loss 0.0033905731979757547\n",
      "2022-03-04 22:30:15.935213 Epoch 290, Training loss 0.0002931655035354197, Validation loss 0.003390492172911763\n",
      "2022-03-04 22:30:15.948225 Epoch 300, Training loss 0.00029316157451830804, Validation loss 0.0033904099836945534\n"
     ]
    }
   ],
   "source": [
    "#Second model with following hidden layer size..\n",
    "#    1st hidden layer =8\n",
    "#    2nd hidden layer = 80\n",
    "#    3rd hidden layer = 20\n",
    "seq_model = nn.Sequential(\n",
    "     nn.Linear(5, 8),\n",
    "     nn.Tanh(),\n",
    "     nn.Linear(8, 80),\n",
    "     nn.Tanh(),\n",
    "     nn.Linear(80, 20),\n",
    "     nn.Tanh(),\n",
    "     nn.Linear(20, 1))\n",
    "\n",
    "optimizer = optim.SGD(seq_model.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 300, \n",
    "    optimizer = optimizer,\n",
    "    model = seq_model,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    t_u_train = t_un_train,\n",
    "    t_u_val = t_un_val, \n",
    "    t_c_train = t_cn_train,\n",
    "    t_c_val = t_cn_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9c1703b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.3680,  0.0168,  0.3054, -0.1204, -0.2191],\n",
       "         [-0.2350,  0.1064,  0.3124, -0.2980,  0.1009],\n",
       "         [-0.2221, -0.3652, -0.3516,  0.2610, -0.0431],\n",
       "         [ 0.0077, -0.0746, -0.2346,  0.1173,  0.0850],\n",
       "         [ 0.3726,  0.2979, -0.1452,  0.0606,  0.2428],\n",
       "         [-0.0017, -0.0534, -0.3270, -0.4190, -0.2532],\n",
       "         [-0.3592,  0.0577,  0.3077,  0.0554,  0.4413],\n",
       "         [ 0.3124,  0.3727,  0.2222,  0.1986, -0.3629]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1436,  0.1177, -0.4347,  0.1773,  0.0767, -0.1565, -0.3452,\n",
       "          0.1435], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.2654, -0.0615,  0.1266,  0.1784,  0.1105,  0.0307, -0.0719,\n",
       "           0.3376],\n",
       "         [ 0.0535,  0.2648, -0.1629, -0.1363,  0.1376, -0.0902, -0.0154,\n",
       "          -0.1303],\n",
       "         [-0.2921,  0.3522, -0.1608, -0.2349,  0.0372,  0.3215,  0.3068,\n",
       "          -0.1119],\n",
       "         [-0.1137, -0.2207,  0.3421, -0.2972,  0.0821,  0.0741, -0.2762,\n",
       "           0.3518],\n",
       "         [-0.0176, -0.1759,  0.3294,  0.2290, -0.1397,  0.2071, -0.3069,\n",
       "          -0.2762],\n",
       "         [ 0.0218,  0.0879,  0.3377,  0.3136, -0.3127,  0.1172, -0.2071,\n",
       "           0.1871],\n",
       "         [-0.3130,  0.1001, -0.3133, -0.2343,  0.0181,  0.1734,  0.0097,\n",
       "          -0.3231],\n",
       "         [ 0.1636,  0.0542,  0.3040, -0.0727, -0.0749, -0.0771,  0.3434,\n",
       "           0.2228],\n",
       "         [ 0.1901, -0.3225,  0.2533,  0.2821,  0.2870,  0.1272,  0.0103,\n",
       "           0.3208],\n",
       "         [ 0.1984, -0.0116, -0.3361, -0.2675, -0.1342, -0.0467, -0.3246,\n",
       "          -0.1592],\n",
       "         [ 0.1229,  0.1038, -0.1107, -0.1094, -0.2314, -0.3520, -0.2211,\n",
       "          -0.1564],\n",
       "         [ 0.0246, -0.1159, -0.2883,  0.0943,  0.1107,  0.2583, -0.3022,\n",
       "           0.1211],\n",
       "         [ 0.1227, -0.0423, -0.2727,  0.1188, -0.1626, -0.0215,  0.2991,\n",
       "           0.1318],\n",
       "         [-0.1230,  0.0361, -0.2170,  0.1400,  0.1132,  0.3450,  0.0962,\n",
       "           0.1661],\n",
       "         [-0.0464,  0.0996,  0.2185,  0.0667,  0.1262,  0.0393, -0.0787,\n",
       "          -0.2876],\n",
       "         [-0.0241, -0.0460, -0.1534, -0.0385, -0.2667,  0.3258,  0.1435,\n",
       "          -0.1544],\n",
       "         [ 0.2972,  0.0080, -0.0142, -0.3242, -0.3386, -0.2696,  0.1950,\n",
       "          -0.0511],\n",
       "         [ 0.0650,  0.0394,  0.2881, -0.2542, -0.3408, -0.0740,  0.1847,\n",
       "           0.3142],\n",
       "         [-0.1821,  0.0334,  0.1275,  0.1438,  0.0602,  0.1990,  0.2754,\n",
       "          -0.2757],\n",
       "         [ 0.1148,  0.2192, -0.1850,  0.0800,  0.0572,  0.2422, -0.1611,\n",
       "           0.0955],\n",
       "         [ 0.1999,  0.2789, -0.0204,  0.1983,  0.2627,  0.3152, -0.3474,\n",
       "          -0.1209],\n",
       "         [ 0.2805,  0.1857, -0.2863,  0.3167, -0.1846,  0.1013, -0.1799,\n",
       "           0.1525],\n",
       "         [ 0.2914,  0.1263, -0.3517, -0.0931, -0.0101,  0.0357, -0.2962,\n",
       "          -0.1966],\n",
       "         [ 0.1824,  0.1228, -0.0591,  0.3478,  0.2958,  0.3482,  0.2847,\n",
       "          -0.0700],\n",
       "         [-0.0171,  0.1437, -0.2350,  0.2221, -0.0512,  0.1138, -0.1859,\n",
       "          -0.3173],\n",
       "         [ 0.1408,  0.0615,  0.2460, -0.0619,  0.2607, -0.2320, -0.3276,\n",
       "           0.1917],\n",
       "         [ 0.1943,  0.1407,  0.1644, -0.3099, -0.3073,  0.2543,  0.2780,\n",
       "          -0.0948],\n",
       "         [-0.0774, -0.1609, -0.1682,  0.1234,  0.2285,  0.2969, -0.2774,\n",
       "           0.0589],\n",
       "         [-0.3024, -0.1645,  0.2748, -0.1970, -0.2156,  0.0979, -0.0750,\n",
       "           0.3149],\n",
       "         [ 0.1660,  0.2633, -0.0873, -0.3005,  0.1511,  0.0399,  0.0661,\n",
       "          -0.3482],\n",
       "         [-0.1751,  0.0204, -0.3436,  0.0758, -0.1945,  0.3442, -0.2366,\n",
       "           0.2347],\n",
       "         [ 0.2261,  0.0727, -0.1616, -0.3409,  0.0867,  0.1608,  0.2126,\n",
       "          -0.2334],\n",
       "         [ 0.2231, -0.3315, -0.1578,  0.2045,  0.1299, -0.2665,  0.2948,\n",
       "          -0.1597],\n",
       "         [-0.1763,  0.3184, -0.3300, -0.1576,  0.3252, -0.1984, -0.0396,\n",
       "          -0.0168],\n",
       "         [ 0.2365, -0.3473,  0.3203,  0.2619, -0.3347,  0.2842, -0.1416,\n",
       "           0.2493],\n",
       "         [-0.2356, -0.0990,  0.1782,  0.2654,  0.0180, -0.3026,  0.2922,\n",
       "          -0.0788],\n",
       "         [ 0.0060, -0.2135, -0.2710,  0.1980,  0.0054, -0.0155, -0.3427,\n",
       "           0.2107],\n",
       "         [-0.3003,  0.2625,  0.3343,  0.1721,  0.0399, -0.1687,  0.0884,\n",
       "           0.0976],\n",
       "         [ 0.1408, -0.3435,  0.0344, -0.1677,  0.2031,  0.2151,  0.2040,\n",
       "           0.0283],\n",
       "         [ 0.0576,  0.2931, -0.1863,  0.2673,  0.3172,  0.1084, -0.1096,\n",
       "           0.1045],\n",
       "         [-0.1512,  0.2032, -0.1488, -0.0926, -0.2490, -0.0706, -0.1367,\n",
       "          -0.0455],\n",
       "         [ 0.3053, -0.0379,  0.2826, -0.1009,  0.1230, -0.2502, -0.1255,\n",
       "          -0.3520],\n",
       "         [-0.0088, -0.2216,  0.2598, -0.1003, -0.3304,  0.3366, -0.3018,\n",
       "          -0.3531],\n",
       "         [ 0.0931,  0.1404, -0.0294,  0.0884, -0.0496, -0.3196,  0.0884,\n",
       "           0.0834],\n",
       "         [-0.1560,  0.1594,  0.1932,  0.2931, -0.0084, -0.2054,  0.3187,\n",
       "          -0.3412],\n",
       "         [ 0.1506,  0.2854, -0.1102,  0.1054, -0.0238, -0.0304, -0.1486,\n",
       "          -0.2067],\n",
       "         [-0.1818, -0.1797,  0.1212,  0.3083,  0.2321, -0.1829, -0.0064,\n",
       "          -0.1706],\n",
       "         [-0.2085,  0.1466,  0.1379, -0.1866,  0.2148, -0.2032,  0.2045,\n",
       "          -0.1495],\n",
       "         [ 0.1188, -0.1045,  0.3072, -0.2115, -0.1853,  0.3442,  0.2159,\n",
       "          -0.0844],\n",
       "         [-0.0345, -0.2229, -0.0316, -0.0645,  0.2036, -0.0353, -0.1373,\n",
       "           0.3162],\n",
       "         [-0.1747, -0.3490, -0.1001, -0.0685, -0.2059, -0.2721, -0.2118,\n",
       "          -0.0390],\n",
       "         [ 0.0690, -0.3171, -0.1288, -0.2744,  0.2319,  0.1041,  0.1889,\n",
       "           0.1345],\n",
       "         [-0.3534, -0.2504, -0.0139,  0.1910,  0.0833,  0.3250, -0.3372,\n",
       "           0.0259],\n",
       "         [ 0.1631,  0.1761,  0.2059, -0.0438,  0.3242, -0.2118, -0.3084,\n",
       "          -0.1578],\n",
       "         [-0.2680, -0.2494,  0.1276,  0.1403,  0.1061,  0.2323, -0.1789,\n",
       "          -0.0146],\n",
       "         [ 0.0145,  0.2699,  0.2222,  0.1986, -0.1852,  0.0258,  0.2649,\n",
       "          -0.2113],\n",
       "         [ 0.2994, -0.1566, -0.1755, -0.2563, -0.2049,  0.3323,  0.0522,\n",
       "           0.2098],\n",
       "         [ 0.0297,  0.1128,  0.0770,  0.0712, -0.2756,  0.0904, -0.3212,\n",
       "          -0.2050],\n",
       "         [-0.2089, -0.1459,  0.2066,  0.0784, -0.3170,  0.2247, -0.0684,\n",
       "           0.2881],\n",
       "         [ 0.0194, -0.2068, -0.3454, -0.2871,  0.1799,  0.1925, -0.2022,\n",
       "          -0.0702],\n",
       "         [-0.1221,  0.3169,  0.0851, -0.0204,  0.3167,  0.1511, -0.2159,\n",
       "           0.2091],\n",
       "         [ 0.1252, -0.0696,  0.2990, -0.1450,  0.0677,  0.2034,  0.1085,\n",
       "           0.1866],\n",
       "         [-0.3211, -0.1419, -0.1039, -0.0838, -0.3100,  0.2869, -0.2825,\n",
       "           0.3040],\n",
       "         [ 0.2858, -0.0573, -0.2912,  0.2841,  0.0139, -0.1873, -0.0062,\n",
       "          -0.2920],\n",
       "         [-0.0474,  0.1830,  0.1456,  0.0159,  0.3082,  0.1354,  0.0775,\n",
       "          -0.0110],\n",
       "         [ 0.2786, -0.2835, -0.0634,  0.1533, -0.2843,  0.0804,  0.1852,\n",
       "          -0.1738],\n",
       "         [-0.1391, -0.0249, -0.1006, -0.2668,  0.2604,  0.1747,  0.0635,\n",
       "           0.3247],\n",
       "         [-0.2802,  0.2027, -0.3325, -0.3002,  0.0817, -0.0150, -0.3061,\n",
       "           0.0412],\n",
       "         [ 0.2463,  0.1182, -0.2635, -0.1009, -0.0376, -0.3256,  0.2242,\n",
       "          -0.2286],\n",
       "         [-0.0077,  0.1626, -0.1346, -0.3255, -0.2364,  0.0238, -0.2602,\n",
       "          -0.2987],\n",
       "         [-0.0947,  0.0899, -0.0719, -0.2844, -0.2325, -0.2673,  0.0030,\n",
       "           0.2387],\n",
       "         [-0.2412, -0.3252, -0.2243, -0.2887, -0.3280, -0.1641,  0.2992,\n",
       "          -0.0714],\n",
       "         [-0.1584, -0.2913, -0.0894, -0.1140, -0.1482, -0.1184, -0.3305,\n",
       "           0.1787],\n",
       "         [ 0.2341, -0.3304, -0.2380, -0.1105, -0.0014, -0.2248,  0.0371,\n",
       "           0.0717],\n",
       "         [-0.2403,  0.1261,  0.1704,  0.0080,  0.1396, -0.1262, -0.0887,\n",
       "           0.0397],\n",
       "         [-0.1778,  0.1704,  0.2539, -0.0594, -0.2814, -0.1710, -0.1342,\n",
       "           0.3337],\n",
       "         [ 0.1304,  0.3535,  0.3053,  0.0984, -0.2291, -0.2041,  0.1131,\n",
       "           0.1664],\n",
       "         [-0.2726,  0.2903,  0.2289, -0.0412,  0.1541,  0.0547, -0.0369,\n",
       "          -0.3372],\n",
       "         [ 0.1811, -0.1632, -0.2077,  0.1651, -0.1714,  0.0626, -0.1727,\n",
       "          -0.1021],\n",
       "         [ 0.0208,  0.3413,  0.0437,  0.0852,  0.1742, -0.0053,  0.0614,\n",
       "           0.2752]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 1.8152e-01, -8.5081e-02,  3.1584e-01,  2.3721e-04, -2.1332e-02,\n",
       "         -1.9863e-01, -1.8268e-01,  2.8971e-01, -3.1561e-01,  1.7606e-01,\n",
       "         -2.4063e-01, -1.4333e-01, -5.4543e-02,  1.5126e-01,  4.3222e-02,\n",
       "          2.9028e-01,  2.4831e-01, -2.0513e-01, -4.1671e-02, -8.7916e-02,\n",
       "         -5.2790e-02, -3.0341e-01, -3.2502e-01,  9.9457e-02,  1.9868e-01,\n",
       "         -3.4017e-01,  2.3808e-01, -2.1628e-01, -3.9679e-02, -2.5780e-01,\n",
       "          3.3102e-01, -2.4626e-01, -2.9245e-01,  1.9127e-01,  3.2368e-01,\n",
       "          2.6004e-01, -3.3349e-01,  1.7306e-01, -8.4314e-02,  1.4657e-01,\n",
       "         -7.0798e-02, -1.9506e-01,  5.9770e-02,  1.3138e-01, -1.7825e-01,\n",
       "         -1.9761e-01, -2.0343e-02, -2.4091e-01, -1.5492e-01,  3.1828e-01,\n",
       "          9.7062e-03, -3.0459e-01, -3.4185e-01,  2.8612e-01,  3.2391e-01,\n",
       "         -3.2136e-01,  1.0706e-01,  3.3267e-01, -3.3783e-01,  2.5738e-01,\n",
       "         -4.3891e-02,  2.7069e-02,  1.8644e-01, -1.3707e-01, -5.4252e-02,\n",
       "         -3.0439e-01, -5.3705e-02,  2.3420e-02, -1.9227e-01,  9.8196e-02,\n",
       "          5.3821e-02, -2.4420e-01,  7.7433e-02,  2.4661e-01, -3.1256e-01,\n",
       "          2.2996e-01,  2.4167e-01,  1.2260e-01,  1.0269e-01, -9.6138e-02],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0907, -0.0281,  ...,  0.0372, -0.0151],\n",
       "         [-0.0399, -0.0256,  ..., -0.0751,  0.0841],\n",
       "         ...,\n",
       "         [ 0.0207, -0.0173,  ...,  0.0580, -0.1009],\n",
       "         [ 0.0404,  0.0762,  ..., -0.0627,  0.0415]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0941,  0.1098, -0.0678,  0.0696,  0.0067,  0.0792, -0.0691,\n",
       "          0.0001, -0.0349,  0.0124, -0.0158, -0.0690, -0.0299,  0.0864,\n",
       "          0.0684,  0.0168,  0.0734,  0.0244,  0.0077,  0.0798],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0313, -0.0473, -0.0462, -0.1547,  0.1678,  0.1460,  0.0821,\n",
       "          -0.1305,  0.0170, -0.1476,  0.1541,  0.1843,  0.0757,  0.2078,\n",
       "          -0.2225,  0.0017,  0.1759,  0.0060, -0.2114,  0.2257]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0461], requires_grad=True)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(seq_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79365f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Sequential(\n",
       "  (0): Linear(in_features=5, out_features=8, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=8, out_features=80, bias=True)\n",
       "  (3): Tanh()\n",
       "  (4): Linear(in_features=80, out_features=20, bias=True)\n",
       "  (5): Tanh()\n",
       "  (6): Linear(in_features=20, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d8a390c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=5, out_features=8, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=8, out_features=80, bias=True)\n",
       "  (3): Tanh()\n",
       "  (4): Linear(in_features=80, out_features=20, bias=True)\n",
       "  (5): Tanh()\n",
       "  (6): Linear(in_features=20, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c05334a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([8, 5]),\n",
       " torch.Size([8]),\n",
       " torch.Size([80, 8]),\n",
       " torch.Size([80]),\n",
       " torch.Size([20, 80]),\n",
       " torch.Size([20]),\n",
       " torch.Size([1, 20]),\n",
       " torch.Size([1])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param.shape for param in seq_model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af3a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5843a8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833134f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1394e50",
   "metadata": {},
   "source": [
    "Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49342e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x28fa116c270>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2657a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2387966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing cifar10 data and loading the training and validation sets \n",
    "from torchvision import datasets, transforms\n",
    "data_path = 'data/'\n",
    "\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "775105e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.4915, 0.4823, 0.4468), std=(0.247, 0.2435, 0.2616))\n",
       "           )"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e5a3705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data/\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.4915, 0.4823, 0.4468), std=(0.247, 0.2435, 0.2616))\n",
       "           )"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55252ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to print out last models parameter count, training accuracy and validation accuracy\n",
    "def model_summary():\n",
    "    print(model)\n",
    "    print(\"Parameter Count:\" , sum([p.numel() for p in model.parameters()]))\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)  # <1>\n",
    "            labels = labels.to(device=device)\n",
    "            batch_size = imgs.shape[0]\n",
    "            outputs = model(imgs.view(batch_size,-1))\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.shape[0]\n",
    "            correct += int((predicted == labels).sum())\n",
    "\n",
    "    print(\"Training Accuracy: %f\" % (correct / total))\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs = imgs.to(device=device)  # <1>\n",
    "            labels = labels.to(device=device)\n",
    "            batch_size = imgs.shape[0]\n",
    "            outputs = model(imgs.view(batch_size,-1))\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.shape[0]\n",
    "            correct += int((predicted == labels).sum())\n",
    "\n",
    "    print(\"Validation Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5141ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating training and validation into batches for faster processing\n",
    "train_loader = torch.utils.data.DataLoader(cifar10, batch_size=50000,\n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=10000,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e21ee6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "#setting device to GPU if applicable \n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "#device =torch.device('cpu') #uncomment if you want to force device=cpu\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75cfb22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-04 22:30:28.634531 Epoch 1, Training loss 2.3361594676971436\n",
      "2022-03-04 22:31:50.483109 Epoch 10, Training loss 2.120896816253662\n",
      "2022-03-04 22:33:22.034329 Epoch 20, Training loss 2.0459649562835693\n",
      "2022-03-04 22:34:54.739624 Epoch 30, Training loss 2.0012950897216797\n",
      "2022-03-04 22:36:27.490730 Epoch 40, Training loss 1.969862937927246\n",
      "2022-03-04 22:38:00.440695 Epoch 50, Training loss 1.9460210800170898\n",
      "2022-03-04 22:39:33.588325 Epoch 60, Training loss 1.9270731210708618\n",
      "2022-03-04 22:41:06.959728 Epoch 70, Training loss 1.9115160703659058\n",
      "2022-03-04 22:42:40.337905 Epoch 80, Training loss 1.8984037637710571\n",
      "2022-03-04 22:44:13.963424 Epoch 90, Training loss 1.8871265649795532\n",
      "2022-03-04 22:45:47.118019 Epoch 100, Training loss 1.8772573471069336\n",
      "2022-03-04 22:47:20.554650 Epoch 110, Training loss 1.8684967756271362\n",
      "2022-03-04 22:48:53.946121 Epoch 120, Training loss 1.8606220483779907\n",
      "2022-03-04 22:50:27.495988 Epoch 130, Training loss 1.8534743785858154\n",
      "2022-03-04 22:52:01.086689 Epoch 140, Training loss 1.8469321727752686\n",
      "2022-03-04 22:53:35.035961 Epoch 150, Training loss 1.8409017324447632\n",
      "2022-03-04 22:55:08.803622 Epoch 160, Training loss 1.8353052139282227\n",
      "2022-03-04 22:56:42.759993 Epoch 170, Training loss 1.8300837278366089\n",
      "2022-03-04 22:58:16.538216 Epoch 180, Training loss 1.8251962661743164\n",
      "2022-03-04 22:59:50.497051 Epoch 190, Training loss 1.8205965757369995\n",
      "2022-03-04 23:01:24.613436 Epoch 200, Training loss 1.8162568807601929\n",
      "2022-03-04 23:02:58.750199 Epoch 210, Training loss 1.8121439218521118\n",
      "2022-03-04 23:04:32.923507 Epoch 220, Training loss 1.8082401752471924\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23764/2046189390.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;31m#added just to format print epoch 1,10,20...200 later on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# <1>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torchvision\\datasets\\cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \"\"\"\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#First model, 1 hidden layer with size of 512\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "\n",
    "model1 = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.LogSoftmax(dim=1)).to(device)\n",
    "\n",
    "model=model1\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss().to(device)\n",
    "\n",
    "n_epochs = 300\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch=epoch+1#added just to format print epoch 1,10,20...200 later on\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs = imgs.to(device=device)  # <1>\n",
    "        labels = labels.to(device=device)\n",
    "        \n",
    "        batch_size = imgs.shape[0]\n",
    "        out = model(imgs.view(batch_size,-1))\n",
    "        loss = loss_fn(out, labels)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch == 1  or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e74dd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3072, out_features=512, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (3): LogSoftmax(dim=1)\n",
      ")\n",
      "Parameter Count: 1578506\n",
      "Training Accuracy: 0.384240\n",
      "Validation Accuracy: 0.381600\n"
     ]
    }
   ],
   "source": [
    "#Using predifined function(self explanitory)\n",
    "model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c52bb6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-04 23:05:23.317439 Epoch 1, Training loss 2.3034963607788086\n",
      "2022-03-04 23:06:47.996251 Epoch 10, Training loss 2.2259438037872314\n",
      "2022-03-04 23:08:21.737090 Epoch 20, Training loss 2.1753599643707275\n",
      "2022-03-04 23:09:55.573467 Epoch 30, Training loss 2.1410210132598877\n",
      "2022-03-04 23:11:29.262195 Epoch 40, Training loss 2.1146578788757324\n",
      "2022-03-04 23:13:02.978067 Epoch 50, Training loss 2.0929579734802246\n",
      "2022-03-04 23:14:36.594106 Epoch 60, Training loss 2.074371814727783\n",
      "2022-03-04 23:16:10.431212 Epoch 70, Training loss 2.0580615997314453\n",
      "2022-03-04 23:17:44.249236 Epoch 80, Training loss 2.0435187816619873\n",
      "2022-03-04 23:19:18.108781 Epoch 90, Training loss 2.0303919315338135\n",
      "2022-03-04 23:20:51.776658 Epoch 100, Training loss 2.018437385559082\n",
      "2022-03-04 23:22:25.648865 Epoch 110, Training loss 2.0074706077575684\n",
      "2022-03-04 23:23:59.269061 Epoch 120, Training loss 1.9973422288894653\n",
      "2022-03-04 23:25:33.169539 Epoch 130, Training loss 1.987939476966858\n",
      "2022-03-04 23:27:07.003638 Epoch 140, Training loss 1.9791765213012695\n",
      "2022-03-04 23:28:41.059288 Epoch 150, Training loss 1.9709748029708862\n",
      "2022-03-04 23:30:15.047685 Epoch 160, Training loss 1.9632729291915894\n",
      "2022-03-04 23:31:48.921592 Epoch 170, Training loss 1.9560189247131348\n",
      "2022-03-04 23:33:23.054058 Epoch 180, Training loss 1.949170470237732\n",
      "2022-03-04 23:34:57.233092 Epoch 190, Training loss 1.9426878690719604\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23764/3808160541.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;31m#added just to format print epoch 1,10,20...200 later on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# <1>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torchvision\\datasets\\cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \"\"\"\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RealTime\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m255\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m     \u001b[1;31m# put it from HWC to CHW format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Third model with following hidden layer size..\n",
    "#    1st hidden layer =4096\n",
    "#    2nd hidden layer = 2048\n",
    "#    3rd hidden layer = 1024\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "\n",
    "model3 = nn.Sequential(\n",
    "            nn.Linear(3072, 4096),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 10),\n",
    "            nn.LogSoftmax(dim=1)).to(device)\n",
    "\n",
    "model=model3\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss().to(device)\n",
    "\n",
    "n_epochs = 300\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch=epoch+1#added just to format print epoch 1,10,20...200 later on\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs = imgs.to(device=device)  # <1>\n",
    "        labels = labels.to(device=device)\n",
    "        \n",
    "        batch_size = imgs.shape[0]\n",
    "        out = model(imgs.view(batch_size,-1))\n",
    "        loss = loss_fn(out, labels)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "678b869e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3072, out_features=4096, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=1024, out_features=64, bias=True)\n",
      "  (5): Tanh()\n",
      "  (6): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (7): LogSoftmax(dim=1)\n",
      ")\n",
      "Parameter Count: 16848586\n",
      "Training Accuracy: 0.327920\n",
      "Validation Accuracy: 0.327900\n"
     ]
    }
   ],
   "source": [
    "#Using predifined function(self explanitory)\n",
    "model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a336a55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
